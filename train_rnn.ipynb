{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "from numpy import nan\n",
    "import requests\n",
    "import os.path\n",
    "from sklearn import preprocessing\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    df = pd.read_hdf('./checkpoints/data_test.h5','table')\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(float_data):\n",
    "    mean = float_data.mean(axis=0)\n",
    "    float_data -= mean\n",
    "    std = float_data.std(axis=0)\n",
    "    float_data /= std\n",
    "    return float_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_test_data()\n",
    "data = normalize_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.37814783e-01, -2.25267417e-05, -7.14610900e-06,\n",
       "        -3.04541430e-05, -3.16574836e-01, -1.18456275e-01],\n",
       "       [-3.37814783e-01, -2.25267417e-05, -7.14610900e-06,\n",
       "        -3.04541430e-05, -3.16574836e-01, -1.18456275e-01],\n",
       "       [-3.37814783e-01, -2.25267417e-05, -7.14610900e-06,\n",
       "        -3.04541430e-05, -3.16574836e-01, -1.18456275e-01],\n",
       "       ...,\n",
       "       [ 1.18226921e+00, -3.73320798e-01,  1.97613972e+00,\n",
       "        -2.01228691e-01,  1.37781913e+00,  4.41700749e-01],\n",
       "       [ 1.18226921e+00, -3.73320798e-01,  1.97613972e+00,\n",
       "        -2.01228691e-01,  1.37781913e+00,  7.21779261e-01],\n",
       "       [ 8.02248215e-01, -3.73320798e-01,  1.97613972e+00,\n",
       "        -2.01228691e-01,  1.37781913e+00,  7.21779261e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coppied from Deep Learning with Python by Francois Chollet\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    \"\"\" Generator yielding timeseries samples and their targets\n",
    "    \n",
    "    Arguments:\n",
    "        data {[type]} -- The original array of floating-point data,\n",
    "        lookback {[type]} -- How many timesteps back the input data should go.\n",
    "        delay {[type]} -- How many timesteps in the future the target should be.\n",
    "        min_index {[type]} -- Indices in the data array that delimit which timesteps to draw from.\n",
    "        max_index {[type]} -- Indices in the data array that delimit which timesteps to draw from.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        shuffle {bool} -- Whether to shuffle the samples or draw them in chronological order. (default: {False})\n",
    "        batch_size {int} -- The number of samples per batch. (default: {128})\n",
    "        step {int} -- The period, in timesteps, at which you sample data. (default: {6})\n",
    "    \"\"\"\n",
    "\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows), data.shape[-1]))\n",
    "        for j, row in enumerate(rows):\n",
    "#             import pdb;pdb.set_trace()\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_val(data, lookback, step):\n",
    "    train_index = int(len(data) * (.5))\n",
    "    test_index = train_index + int(len(data) * (.25))\n",
    "\n",
    "    delay = 1440\n",
    "    \n",
    "    train_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=0,\n",
    "                         max_index=train_index,\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    test_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=train_index + 1,\n",
    "                         max_index=test_index,\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    val_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=test_index + 1,\n",
    "                         max_index=len(data),\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    val_steps = (len(data) - (test_index +1) - lookback) // 128\n",
    "    \n",
    "    test_steps = (test_index - (train_index +1) - lookback) // 128\n",
    "    \n",
    "    return train_gen, test_gen, val_gen, val_steps, test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_generator(data):\n",
    "    yield 68, 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(float_data, lookback, step):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(10080, float_data.shape[-1])))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(float_data.shape[-1]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    lookback = 10080\n",
    "    step = 1\n",
    "    \n",
    "    float_data = get_test_data()\n",
    "    normalized_data = normalize_data(float_data)\n",
    "    train_gen, test_gen, val_gen, val_steps, test_steps = get_train_test_val(normalized_data, lookback, step)\n",
    "    \n",
    "    model = get_model(normalized_data, lookback, step)    \n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=RMSprop(), loss='mae', metrics=['acc'])\n",
    "    history = model.fit_generator(train_gen,\n",
    "                                 steps_per_epoch=500,\n",
    "                                 epochs=40,\n",
    "                                 validation_data=val_gen, \n",
    "                                 validation_steps=val_steps) \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 60480)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1935392   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 1,935,590\n",
      "Trainable params: 1,935,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/40\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.6694 - acc: 0.0091"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
