{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "from numpy import nan\n",
    "import requests\n",
    "import os.path\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    df = pd.read_hdf('./checkpoints/data_test.h5','table')\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(float_data):\n",
    "    mean = float_data.mean(axis=0)\n",
    "    float_data -= mean\n",
    "    std = float_data.std(axis=0)\n",
    "    float_data /= std\n",
    "    return float_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_test_data()\n",
    "data = normalize_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coppied from Deep Learning with Python by Francois Chollet\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    \"\"\" Generator yielding timeseries samples and their targets\n",
    "    \n",
    "    Arguments:\n",
    "        data {[type]} -- The original array of floating-point data,\n",
    "        lookback {[type]} -- How many timesteps back the input data should go.\n",
    "        delay {[type]} -- How many timesteps in the future the target should be.\n",
    "        min_index {[type]} -- Indices in the data array that delimit which timesteps to draw from.\n",
    "        max_index {[type]} -- Indices in the data array that delimit which timesteps to draw from.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        shuffle {bool} -- Whether to shuffle the samples or draw them in chronological order. (default: {False})\n",
    "        batch_size {int} -- The number of samples per batch. (default: {128})\n",
    "        step {int} -- The period, in timesteps, at which you sample data. (default: {6})\n",
    "    \"\"\"\n",
    "\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_val(data):\n",
    "    train_index = int(len(data) * (.5))\n",
    "    test_index = train_index + int(len(data) * (.25))\n",
    "    \n",
    "    lookback = 10080\n",
    "    step = 1\n",
    "    delay = 1440\n",
    "    \n",
    "    train_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=0,\n",
    "                         max_index=train_index,\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    test_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=train_index + 1,\n",
    "                         max_index=test_index,\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    val_gen = generator(data,\n",
    "                         lookback=lookback,\n",
    "                         delay=delay,\n",
    "                         min_index=test_index + 1,\n",
    "                         max_index=len(data),\n",
    "                         step=step\n",
    "                         )\n",
    "    \n",
    "    val_steps = (len(data) - (test_index +1) - lookback) // 128\n",
    "    \n",
    "    test_steps = (test_index - (train_index +1) - lookback) // 128\n",
    "    \n",
    "    return train_gen, test_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(float_data):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "    model.add(Dense(32), activation='relu')\n",
    "    model.add(Dense(len(float_data.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    float_data = get_test_data()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
