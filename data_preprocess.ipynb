{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up data, convert to dataframes, and save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BAC file is pipe separated with the following fields:\n",
    "LogLevel [TimeStamp]:[LogVisibility][LogSeverity][entryType][entrySubType][eventType][EventType dependent strings]\n",
    "\n",
    "The information changes at the end of each entry based on its EventType.  Here is a list of the supported event types and the subsequent additional information for each listed below.\n",
    "\n",
    "GeneralMessage - [string message]\n",
    "\n",
    "LevelChangedEvent - [load ID][loadName][roomName][rampTime][rampBaseValue][rampFinalValue]\n",
    "\n",
    "ButtonChangedEvent - [keypad ID][keypadName][roomName][buttonNum][buttonState]\n",
    "\n",
    "RemoteSystemEvent - [signalID][signalName][roomName][RemoteSystemEvent string]\n",
    "TimeClockChangedEvent/OccupancyChangedEvent/SceneChangedEvent - [ID][name][roomName][message]\n",
    "\n",
    "ConnectionStatus - [device ID][Name][room Name][connection status][Load 1 Room Name:Load 1 Name]|[Load 2 Room Name:Load 2 Name]\n",
    "\n",
    "    NOTE: DeviceConnectionStatusWithOptions is the same format as ConnectionStatus. \n",
    "    \n",
    "SignalChangedEvent - [device ID][Device Name][room Name][signal event ID][signal Value] - Signal event ID differs by device and signal value is either bool or int based on the eventID.\n",
    "\n",
    "SignalChangedEventWithStrings - [device ID][Device Name][Signal Name][Signal Value string][Signal direction][message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:09:58.810044Z",
     "start_time": "2018-06-08T21:08:58.850Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "from numpy import nan\n",
    "from datetime import datetime, timedelta, date\n",
    "from fractions import Fraction\n",
    "from time import mktime\n",
    "import time\n",
    "import requests\n",
    "import os.path\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:03:43.036724Z",
     "start_time": "2018-06-08T21:03:43.030834Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_or_load_from_checkpoint(checkpoint_name):\n",
    "    if os.path.isfile(checkpoint_name):\n",
    "        return pd.read_hdf(checkpoint_name,'table')\n",
    "    df.to_hdf(checkpoint_name, 'table', mode='w', append=True, complevel=9, complib='zlib', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:03:45.111269Z",
     "start_time": "2018-06-08T21:03:44.906930Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['LogLevel',\n",
    "          'TimeStamp',\n",
    "          'LogVisibility',\n",
    "          'LogSeverity',\n",
    "          'entryType',\n",
    "          'entrySubType',\n",
    "          'eventType']\n",
    "# from label list\n",
    "EVENT_TYPE_INDEX = labels.index('eventType')\n",
    "\n",
    "# from line in .bac file\n",
    "LOG_LEVEL_START = 0\n",
    "LOG_LEVEL_END = 3\n",
    "TIMESTAMP_START = 6\n",
    "TIMESTAMP_END = 14\n",
    "PIPE_SEPARATED_DATA_START = 17\n",
    "\n",
    "event_type_labels = [\n",
    "    \"string message\", # GeneralMessage\n",
    "    \"load ID\", \"loadName\", \"roomName1\", \"rampTime\", \"rampBaseValue\", \"rampFinalValue\", # LevelChangedEvent\n",
    "    \"keypad ID\", \"keypadName\", \"roomName2\", \"buttonNum\", \"buttonState\", # ButtonChangedEvent\n",
    "    \"signalID\", \"signalName\", \"roomName3\", \"RemoteSystemEvent string\", # RemoteSystemEvent\n",
    "    \"ID\", \"name\", \"roomName4\", \"message1\", # TimeClockChangedEvent/OccupancyChangedEvent/SceneChangedEvent\n",
    "    \"device ID1\", \"Name\", \"roomName5\", \"connection status\", \"Load 1 Room Name:Load 1 Name\", \"Load 2 Room Name:Load 2 Name\", # ConnectionStatus/DeviceConnectionStatusWithOptions\n",
    "    \"device ID2\", \"Device Name1\", \"roomName6\", \"signal event ID\", \"signal Value\", # SignalChangedEvent\n",
    "    \"device ID3\", \"Device Name2\", \"Signal Name\", \"Signal Value string\", \"Signal direction\", \"message2\", # SignalChangedEventWithStrings\n",
    "]\n",
    "\n",
    "def from_bac():\n",
    "    # device_id_offsets = [i for i, x in enumerate(event_type_labels) if x == \"device ID\"]\n",
    "    clean_lines = []\n",
    "\n",
    "    for log in os.listdir('data'):\n",
    "        with open('data/{}'.format(log)) as logfile:\n",
    "            for line in logfile:\n",
    "                line = line.rstrip('\\n')\n",
    "                if line[-1] == '|':\n",
    "                    line = line[:-1]\n",
    "                all_data = ([line[LOG_LEVEL_START:LOG_LEVEL_END], line[TIMESTAMP_START:TIMESTAMP_END]]\n",
    "                            + line[PIPE_SEPARATED_DATA_START:].split('|'))\n",
    "\n",
    "                event_type_dependent_strings = all_data[len(labels):]\n",
    "                clean_line = all_data[:len(labels)]\n",
    "\n",
    "                START_INDEX = 7\n",
    "                if clean_line[EVENT_TYPE_INDEX] == 'GeneralMessage':\n",
    "                    START_INDEX += event_type_labels.index('string message')\n",
    "                    # account for pipes in the message string\n",
    "                    event_type_dependent_strings = ['|'.join(event_type_dependent_strings)]\n",
    "                    assert START_INDEX == 7\n",
    "                    assert len(event_type_dependent_strings) == 1, event_type_dependent_strings\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'LevelChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('load ID')\n",
    "                    assert START_INDEX == 8\n",
    "                    assert len(event_type_dependent_strings) == 6\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'ButtonChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('keypad ID')\n",
    "                    assert START_INDEX == 14\n",
    "                    assert len(event_type_dependent_strings) == 5\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'RemoteSystemEvent':\n",
    "                    START_INDEX += event_type_labels.index('signalID')\n",
    "                    assert START_INDEX == 19\n",
    "                    assert len(event_type_dependent_strings) == 4\n",
    "\n",
    "                elif (clean_line[EVENT_TYPE_INDEX] == 'TimeClockChangedEvent' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'OccupancyChangedEvent' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'SceneChangedEvent'):\n",
    "                    START_INDEX += event_type_labels.index('ID')\n",
    "                    assert START_INDEX == 23\n",
    "                    assert len(event_type_dependent_strings) == 4\n",
    "\n",
    "                elif (clean_line[EVENT_TYPE_INDEX] == 'ConnectionStatus' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'DeviceConnectionStatusWithOptions'):\n",
    "                    START_INDEX += event_type_labels.index('device ID1')\n",
    "                    assert START_INDEX == 27\n",
    "                    assert (len(event_type_dependent_strings) == 4 or\n",
    "                            len(event_type_dependent_strings) == 5 or\n",
    "                            len(event_type_dependent_strings) == 6)\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'SignalChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('device ID2')\n",
    "                    assert START_INDEX == 33\n",
    "                    assert len(event_type_dependent_strings) == 5\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'SignalChangedEventWithStrings':\n",
    "                    START_INDEX += event_type_labels.index('device ID3')\n",
    "                    assert START_INDEX == 38\n",
    "                    # to correct for the double pipe in \"Basement Mudroom\"\n",
    "                    event_type_dependent_strings = [i for i in event_type_dependent_strings if i]\n",
    "                else:\n",
    "                    raise ValueError(\"Wrong event type: {}\".format(clean_line[EVENT_TYPE_INDEX]))\n",
    "\n",
    "                clean_line = clean_line + [np.nan]*len(event_type_labels) + [log[-14:-4]]\n",
    "                clean_line[START_INDEX:START_INDEX + len(event_type_dependent_strings)] = event_type_dependent_strings\n",
    "                clean_lines.append(clean_line)\n",
    "    df = pd.DataFrame(clean_lines, columns=labels + event_type_labels + [\"date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from BAC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:23:00.578019Z",
     "start_time": "2018-06-08T20:22:45.059544Z"
    }
   },
   "outputs": [],
   "source": [
    "df = from_bac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:23:00.586871Z",
     "start_time": "2018-06-08T20:23:00.580257Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_datetime(row):\n",
    "    new_date = row['date'] + ' ' + row['TimeStamp']\n",
    "    dt = datetime.strptime(new_date, '%Y-%m-%d %H:%M:%S')\n",
    "    dt = dt + timedelta(hours=4)\n",
    "    unix_secs = mktime(dt.timetuple())\n",
    "    return unix_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:23:58.951447Z",
     "start_time": "2018-06-08T20:23:00.590325Z"
    }
   },
   "outputs": [],
   "source": [
    "df['unix_time'] = df.apply(to_datetime, axis=1)\n",
    "df = df.drop([\"TimeStamp\",\"date\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:24:02.816549Z",
     "start_time": "2018-06-08T20:23:58.954004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useless columns\n",
    "df = df.drop([\"LogLevel\", \"LogVisibility\", \"LogSeverity\"],axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting General Message\n",
    "df = df.drop(\"string message\", axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Button Change Event\n",
    "df = df.drop([\"keypad ID\", \"keypadName\", \"roomName2\", \"buttonNum\", \"buttonState\"], axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Connection Status\n",
    "df = df.drop([\"device ID1\", \"Name\", \"roomName5\", \"connection status\", \"Load 1 Room Name:Load 1 Name\", \"Load 2 Room Name:Load 2 Name\"], axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Remote System Event\n",
    "df = df.drop([\"signalID\", \"signalName\", \"roomName3\", \"RemoteSystemEvent string\"], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove useless event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:24:06.662246Z",
     "start_time": "2018-06-08T20:24:02.819377Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['eventType'] != 'ButtonChangedEvent']\n",
    "df = df[df['eventType'] != 'GeneralMessage']\n",
    "df = df[df['eventType'] != 'RemoteSystemEvent']\n",
    "df = df[df['eventType'] != 'TimeClockChangedEvent']\n",
    "df = df[df['eventType'] != 'ConnectionStatus']\n",
    "df = df[df['eventType'] != 'DeviceConnectionStatusWithOptions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Ids and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:18.212363Z",
     "start_time": "2018-06-08T20:30:15.653329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge room names\n",
    "df['room_name_merged'] = df['roomName1'].fillna('') + df['roomName4'].fillna('') + df['roomName6'].fillna('')\n",
    "df = df.drop([\"roomName1\",\"roomName4\",\"roomName6\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:20.351864Z",
     "start_time": "2018-06-08T20:30:18.216275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge device name\n",
    "df['device_name'] = df['loadName'].fillna('') + df['name'].fillna('') + df['Device Name1'].fillna('') + df['Device Name2'].fillna('')\n",
    "df = df.drop([\"loadName\", \"name\", \"Device Name1\", \"Device Name2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:22.243510Z",
     "start_time": "2018-06-08T20:30:20.354830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge IDs \n",
    "df['device_id'] = df['load ID'].fillna('') + df['ID'].fillna('') + df['device ID2'].fillna('') + df['device ID3'].fillna('')\n",
    "df = df.drop(['load ID', 'ID', 'device ID2', 'device ID3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:23.600670Z",
     "start_time": "2018-06-08T20:30:22.247009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge messages \n",
    "df['message_merged'] = df['message1'].fillna('') + df['message2'].fillna('')\n",
    "df = df.drop([\"message1\", \"message2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:25.412362Z",
     "start_time": "2018-06-08T20:30:23.603498Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.replace('', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine device name and id to for truly unique ids\n",
    "\n",
    "The devices had no unique identifier stored. We created unique identifiers for each device by combining device_name and device_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:32.390998Z",
     "start_time": "2018-06-08T20:30:31.976083Z"
    }
   },
   "outputs": [],
   "source": [
    "df['device_id_name'] = df['device_id'].astype(str) + df['device_name'].astype(str)\n",
    "# df = df.drop([\"device_id\", \"device_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:30:36.931414Z",
     "start_time": "2018-06-08T20:30:33.580647Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:31:46.539007Z",
     "start_time": "2018-06-08T20:30:43.516452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checkpoint \n",
    "df = save_or_load_from_checkpoint('./checkpoints/data_0.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:31:47.381761Z",
     "start_time": "2018-06-08T20:31:46.541172Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# dropping more useless data\n",
    "index_to_drop = df.loc[df[\"entryType\"] == \"Auxiliary\"][df['eventType'] == \"SignalChangedEventWithStrings\"].index.tolist()\n",
    "df = df.drop(index_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:32:29.145887Z",
     "start_time": "2018-06-08T20:32:29.138722Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_setpoints(row):\n",
    "    signal_direction = str(row['Signal direction'])\n",
    "    temp = np.nan\n",
    "    if 'Fahrenheit' in signal_direction and signal_direction[0].isdigit():\n",
    "        temp = int(''.join(x for x in signal_direction if x.isdigit()))\n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:32:40.935792Z",
     "start_time": "2018-06-08T20:32:30.423080Z"
    }
   },
   "outputs": [],
   "source": [
    "df['temperature'] = df.apply(get_setpoints, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:36:46.823052Z",
     "start_time": "2018-06-08T20:36:29.717257Z"
    }
   },
   "outputs": [],
   "source": [
    "df = save_or_load_from_checkpoint('./checkpoints/data_1.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:38:12.496229Z",
     "start_time": "2018-06-08T20:38:12.492206Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_signal_direction(df, string_val):\n",
    "    return df[df[\"Signal Value string\"] == string_val]['Signal direction'].unique().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:38:15.976776Z",
     "start_time": "2018-06-08T20:38:13.833877Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heat Setpoint ['71° Fahrenheit' '68° Fahrenheit' '69° Fahrenheit' '70° Fahrenheit'\n",
      " '67° Fahrenheit' '72° Fahrenheit' '0° Fahrenheit' '66° Fahrenheit'\n",
      " '73° Fahrenheit' '65° Fahrenheit' '64° Fahrenheit' '63° Fahrenheit'\n",
      " '62° Fahrenheit' '61° Fahrenheit' '60° Fahrenheit' '74° Fahrenheit']\n",
      "Mode ['Heat' 'Cool' 'Off']\n",
      "Auto Setpoint ['73° Fahrenheit' '74° Fahrenheit' '75° Fahrenheit' '76° Fahrenheit'\n",
      " '77° Fahrenheit' '72° Fahrenheit' '70° Fahrenheit' '0° Fahrenheit']\n",
      "Scheduled Setpoints ['Heat = 71° Fahrenheit, Cool = 75° Fahrenheit, and Auto = 72° Fahrenheit'\n",
      " 'Heat = 71° Fahrenheit, Cool = 74° Fahrenheit, and Auto = 72° Fahrenheit'\n",
      " 'Heat = 68° Fahrenheit, Cool = 74° Fahrenheit, and Auto = 72° Fahrenheit'\n",
      " 'Heat = 67° Fahrenheit, Cool = 77° Fahrenheit, and Auto = 72° Fahrenheit'\n",
      " 'Heat = 67° Fahrenheit, Cool = 72° Fahrenheit, and Auto = 72° Fahrenheit'\n",
      " 'Heat = 71° Fahrenheit, Cool = 74° Fahrenheit, and Auto = 70° Fahrenheit'\n",
      " 'Heat = 67° Fahrenheit, Cool = 71° Fahrenheit, and Auto = 73° Fahrenheit'\n",
      " 'Heat = 67° Fahrenheit, Cool = 73° Fahrenheit, and Auto = 73° Fahrenheit']\n",
      "\"Return\" Event ['Heat Setpoint 71° Fahrenheit, Cool Setpoint 74° Fahrenheit, and Auto Setpoint 72° Fahrenheit']\n",
      "Auto Mode ['Enabled' 'Disabled']\n",
      "Single Setpoint Mode ['Disabled']\n",
      "\"Sleep\" Event ['Heat Setpoint 67° Fahrenheit, Cool Setpoint 77° Fahrenheit, and Auto Setpoint 72° Fahrenheit'\n",
      " 'Heat Setpoint 67° Fahrenheit, Cool Setpoint 72° Fahrenheit, and Auto Setpoint 72° Fahrenheit'\n",
      " 'Heat Setpoint 67° Fahrenheit, Cool Setpoint 71° Fahrenheit, and Auto Setpoint 73° Fahrenheit'\n",
      " 'Heat Setpoint 67° Fahrenheit, Cool Setpoint 73° Fahrenheit, and Auto Setpoint 73° Fahrenheit']\n",
      "\"Leave\" Event ['Heat Setpoint 68° Fahrenheit, Cool Setpoint 74° Fahrenheit, and Auto Setpoint 72° Fahrenheit']\n",
      "Unlock ['FromDevice' 'ToDevice']\n",
      "Get Information ['ToDevice']\n",
      "Slab 5B ['Inactive']\n",
      "Humidity View ['Enabled']\n",
      "Slab 2 ['Inactive']\n",
      "Heat Stage 1 ['Active' 'Inactive']\n",
      "Cool Stage 1 ['Inactive' 'Active']\n",
      "Active Fan Level ['Off' 'High']\n",
      "Fan ['On' 'Auto']\n",
      "Hold ['On' 'Off']\n",
      "Humidifier Enable ['Inactive']\n",
      "\"Wake\" Event ['Heat Setpoint 71° Fahrenheit, Cool Setpoint 75° Fahrenheit, and Auto Setpoint 72° Fahrenheit'\n",
      " 'Heat Setpoint 71° Fahrenheit, Cool Setpoint 74° Fahrenheit, and Auto Setpoint 72° Fahrenheit']\n",
      "Lock ['ToDevice' 'FromDevice']\n",
      "Slab Setpoint ['70° Fahrenheit']\n",
      "Slab 4B ['Inactive']\n",
      "Slab 1 ['Inactive']\n",
      "Slab 3 ['Inactive']\n",
      "Humidity Mode ['Enabled']\n",
      "Temperature ['71° Fahrenheit' '72° Fahrenheit' '74° Fahrenheit' '75° Fahrenheit'\n",
      " '73° Fahrenheit' '77° Fahrenheit' '78° Fahrenheit' '76° Fahrenheit'\n",
      " '79° Fahrenheit' '69° Fahrenheit' '70° Fahrenheit' '68° Fahrenheit'\n",
      " '67° Fahrenheit' '66° Fahrenheit' '65° Fahrenheit' '64° Fahrenheit'\n",
      " '32° Fahrenheit' '63° Fahrenheit' '62° Fahrenheit' '0° Fahrenheit'\n",
      " '61° Fahrenheit' '60° Fahrenheit' '59° Fahrenheit' '122° Fahrenheit'\n",
      " '121° Fahrenheit' '120° Fahrenheit' '119° Fahrenheit' '118° Fahrenheit']\n",
      "\"Wake Weekend\" Event ['Heat Setpoint 71° Fahrenheit, Cool Setpoint 74° Fahrenheit, and Auto Setpoint 70° Fahrenheit']\n",
      "Floor Warming ['Heat:False' 'Off:False' 'Off:True']\n",
      "Cool Mode ['Enabled']\n",
      "Slab Temperature ['32° Fahrenheit' '0° Fahrenheit']\n",
      "Humidifier Off ['Inactive' 'Active']\n",
      "Cool Setpoint ['73° Fahrenheit' '74° Fahrenheit' '75° Fahrenheit' '76° Fahrenheit'\n",
      " '77° Fahrenheit' '72° Fahrenheit' '71° Fahrenheit' '70° Fahrenheit'\n",
      " '69° Fahrenheit' '0° Fahrenheit' '78° Fahrenheit' '79° Fahrenheit'\n",
      " '80° Fahrenheit' '81° Fahrenheit' '68° Fahrenheit']\n",
      "\"Weekend Wake\" Event ['Heat Setpoint 71° Fahrenheit, Cool Setpoint 74° Fahrenheit, and Auto Setpoint 70° Fahrenheit']\n",
      "Slab 4A ['Inactive']\n",
      "Auto Deadband ['2° Fahrenheit']\n",
      "Heat Mode ['Enabled']\n",
      "nan []\n",
      "Humidity Setpoint ['5%']\n",
      "Slab 5A ['Inactive']\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for i in sorted(df[\"Signal Value string\"].astype(str).unique()):\n",
    "    d[i] = check_signal_direction(df, i)\n",
    "for k,v in d.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:38:36.551105Z",
     "start_time": "2018-06-08T20:38:36.545410Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'Active Fan Level' : ['High','Off'],\n",
    "'Auto Mode': ['Enabled', 'Disabled'],\n",
    "'Cool Stage 1' : ['Active', 'Inactive'],\n",
    "'Fan' : ['On', 'Auto'],\n",
    "'Floor Warming' : ['Heat:False','Off:False', 'Off:True'],\n",
    "'Heat Stage 1' : ['Active', 'Inactive'],\n",
    "'Hold' : ['On', 'Off'],\n",
    "'Humidifier Off' : ['Inactive', 'Active'],\n",
    "'Mode' : ['Heat' 'Cool' 'Off']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:40:13.741247Z",
     "start_time": "2018-06-08T20:40:13.732457Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_binary(row, **kwargs):\n",
    "    \"\"\"kwargs = [Signal Value, values_dict]\"\"\"\n",
    "    if str(row['eventType']) == 'SignalChangedEventWithStrings':\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for key, values in kwargs.items():\n",
    "            if str(row['Signal Value string']) == key:\n",
    "                for val in values:\n",
    "                    if str(row['Signal direction']) == val:\n",
    "                        return key + val\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:40:30.959683Z",
     "start_time": "2018-06-08T20:40:14.895362Z"
    }
   },
   "outputs": [],
   "source": [
    "df['event'] = df.apply(is_binary, **d, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:40:30.970162Z",
     "start_time": "2018-06-08T20:40:30.962391Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_locked_or_occupied(row):\n",
    "    if str(row['eventType']) == 'OccupancyChangedEvent':\n",
    "        return row['message_merged']\n",
    "    elif str(row['Signal Value string']) == 'Lock' or str(row['Signal Value string']) == 'Unlock':\n",
    "        return row['entryType'] + row['Signal Value string']\n",
    "    elif pd.notna(row['event']):\n",
    "        return str(row['event'])\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:41:01.626553Z",
     "start_time": "2018-06-08T20:40:30.974134Z"
    }
   },
   "outputs": [],
   "source": [
    "df['event'] = df.apply(is_locked_or_occupied, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:41:35.809237Z",
     "start_time": "2018-06-08T20:41:35.780417Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_value(row):\n",
    "    value = np.nan\n",
    "    if pd.notna(row['rampFinalValue']):\n",
    "        value = int(row['rampFinalValue'])\n",
    "    elif pd.notna(row['temperature']):\n",
    "        value = int(row['temperature'])\n",
    "    elif str(row['entryType']) == 'Shades' and str(row['eventType']) == 'SceneChangedEvent':\n",
    "        base_str = str(row['device_id_name'])\n",
    "        split_str = base_str.split(' ')\n",
    "        first_str = split_str[0][-3:]\n",
    "        is_closed = True if split_str[1] == 'Closed' else False\n",
    "        if first_str[-1].isdigit():\n",
    "            frac = float(Fraction(first_str))\n",
    "            if is_closed:\n",
    "                frac = 1 - frac\n",
    "            value = frac\n",
    "        elif is_closed:\n",
    "            value = 0\n",
    "        else:\n",
    "            value = 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:41:58.822372Z",
     "start_time": "2018-06-08T20:41:37.488541Z"
    }
   },
   "outputs": [],
   "source": [
    "df['value'] = df.apply(get_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:41:58.832190Z",
     "start_time": "2018-06-08T20:41:58.825695Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_event_type(row): \n",
    "    event_type = np.nan\n",
    "    if pd.notna(row['value']):\n",
    "        event_type = str(row['entryType'])\n",
    "    return event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:42:13.526581Z",
     "start_time": "2018-06-08T20:41:58.836003Z"
    }
   },
   "outputs": [],
   "source": [
    "df['regression_value_type'] = df.apply(get_event_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:04:11.434007Z",
     "start_time": "2018-06-08T21:03:53.742767Z"
    }
   },
   "outputs": [],
   "source": [
    "df = save_or_load_from_checkpoint('./checkpoints/data_2.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:04:22.815668Z",
     "start_time": "2018-06-08T21:04:22.588321Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['device_id_name', 'event', 'regression_value_type', 'value', 'unix_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add week, day, month, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:04:33.533889Z",
     "start_time": "2018-06-08T21:04:29.035081Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_dates(data_frame):\n",
    "    date = pd.to_datetime(data_frame['unix_time'], unit='s')\n",
    "    data_frame['week'] = date.dt.week\n",
    "    data_frame['day'] = date.dt.day\n",
    "    data_frame['month'] = date.dt.month\n",
    "    data_frame['hour'] = date.dt.hour\n",
    "    data_frame['minute'] = date.dt.minute\n",
    "    data_frame['second'] = date.dt.second\n",
    "    return data_frame\n",
    "\n",
    "df = add_dates(df)\n",
    "df = df.drop('unix_time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:21:34.126326Z",
     "start_time": "2018-06-08T21:21:34.114141Z"
    }
   },
   "source": [
    "### Add temperature, sunrise/sunset data\n",
    "\n",
    "Here we use the darksky weather API to store data about the weather on each given day in a local temperature_data.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp_time_dict(data_frame):\n",
    "    base_http = 'https://api.darksky.net/forecast/00168b91b5fdeb9c6e1c91b0a0b5da9f/39.833851,-74.871826,'\n",
    "    temp_time_dict = {}\n",
    "    \n",
    "    count=0\n",
    "    for index, row in data_frame.iterrows():\n",
    "        date_obj = date(2017, row['month'], row['day'])\n",
    "        current_timestamp = int(time.mktime(date_obj.timetuple())) + 4 * 60 * 60\n",
    "\n",
    "        if not current_timestamp in temp_time_dict.keys():\n",
    "            r = requests.get(base_http + str(current_timestamp))\n",
    "            temp_json = r.json()\n",
    "            temp_time_dict[current_timestamp] = temp_json\n",
    "    \n",
    "#     with open('temperature_data.json', 'w') as outfile:\n",
    "#         json.dump(temp_time_dict, outfile)\n",
    "        \n",
    "    return temp_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = create_temp_time_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data = None\n",
    "# with open('temperature_data.json') as f:\n",
    "#     json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the json object we just created, we pull the hourly temperature, and determine whether the sun was up or down \n",
    "for each row in the data. We add two rows to the dataframe, 'sun', and 'outside_temperature'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:19:48.355461Z",
     "start_time": "2018-06-08T21:19:48.335077Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_weather_sunset_columns(row):\n",
    "    #hard-coded year for now. \n",
    "    date_obj = date(2017, row['month'], row['day'])\n",
    "    #format for API\n",
    "    current_timestamp = int(time.mktime(date_obj.timetuple())) + 4 * 60 * 60\n",
    "    \n",
    "    temperature_info = json_data[current_timestamp]['hourly']['data'][row['hour']]['temperature']\n",
    "    sunrise = json_data[current_timestamp]['daily']['data'][0]['sunriseTime'] #in GMT \n",
    "    sunset = json_data[current_timestamp]['daily']['data'][0]['sunsetTime']\n",
    "    current_timestamp_with_seconds = current_timestamp + (row['hour'] * 60 * 60) + (row['minute'] * 60)\n",
    "\n",
    "    is_sun_up = 1 if sunrise <= current_timestamp_with_seconds <= sunset else 0\n",
    "    return is_sun_up, temperature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T21:19:51.682361Z",
     "start_time": "2018-06-08T21:19:51.195006Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sun'], df['outside_temperature'] = zip(*df.apply(create_weather_sunset_columns, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_or_load_from_checkpoint('./checkpoints/data_3.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Encode Columns\n",
    "\n",
    "Convert Categorical to Numerical Data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "columns_to_update = [\"device_id_name\", \"event\", \"regression_value_type\"]\n",
    "\n",
    "def encode_columns(data_frame, column_names):\n",
    "    label_encoders = {}\n",
    "    for col in column_names:\n",
    "        values = data_frame[col].unique()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(values)\n",
    "        label_encoders[col] = le\n",
    "        numerical_values = le.transform(data_frame[col])\n",
    "        data_frame[col] = numerical_values\n",
    "    return data_frame, label_encoders\n",
    "\n",
    "categorical_df = df.copy()\n",
    "# to encode the df we need to encode the NaNs as strings\n",
    "categorical_df = categorical_df.fillna({'regression_value_type':'nan', 'event': 'nan', 'value':0})\n",
    "categorical_df, label_encoders = encode_columns(categorical_df, columns_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.to_hdf('./checkpoints/data_categorical.h5', 'table', mode='w', append=True, complevel=9, complib='zlib', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
