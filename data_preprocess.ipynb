{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up data, convert to dataframes, and save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BAC file is pipe separated with the following fields:\n",
    "LogLevel [TimeStamp]:[LogVisibility][LogSeverity][entryType][entrySubType][eventType][EventType dependent strings]\n",
    "\n",
    "The information changes at the end of each entry based on its EventType.  Here is a list of the supported event types and the subsequent additional information for each listed below.\n",
    "\n",
    "GeneralMessage - [string message]\n",
    "\n",
    "LevelChangedEvent - [load ID][loadName][roomName][rampTime][rampBaseValue][rampFinalValue]\n",
    "\n",
    "ButtonChangedEvent - [keypad ID][keypadName][roomName][buttonNum][buttonState]\n",
    "\n",
    "RemoteSystemEvent - [signalID][signalName][roomName][RemoteSystemEvent string]\n",
    "TimeClockChangedEvent/OccupancyChangedEvent/SceneChangedEvent - [ID][name][roomName][message]\n",
    "\n",
    "ConnectionStatus - [device ID][Name][room Name][connection status][Load 1 Room Name:Load 1 Name]|[Load 2 Room Name:Load 2 Name]\n",
    "\n",
    "    NOTE: DeviceConnectionStatusWithOptions is the same format as ConnectionStatus. \n",
    "    \n",
    "SignalChangedEvent - [device ID][Device Name][room Name][signal event ID][signal Value] - Signal event ID differs by device and signal value is either bool or int based on the eventID.\n",
    "\n",
    "SignalChangedEventWithStrings - [device ID][Device Name][Signal Name][Signal Value string][Signal direction][message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DATA ANALYSIS PUT HOUR, DAY, WEEK, MONTH, DATE, WEATHER, SUNRISE/SUNUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from numpy import nan\n",
    "from datetime import datetime, timedelta\n",
    "from time import mktime\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import os.path\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_or_load_from_checkpoint(checkpoint_name):\n",
    "    if os.path.isfile(checkpoint_name):\n",
    "        return pd.read_hdf(checkpoint_name,'table')\n",
    "    df.to_hdf(checkpoint_name, 'table', mode='w', append=True, complevel=9, complib='zlib', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['LogLevel',\n",
    "          'TimeStamp',\n",
    "          'LogVisibility',\n",
    "          'LogSeverity',\n",
    "          'entryType',\n",
    "          'entrySubType',\n",
    "          'eventType']\n",
    "# from label list\n",
    "EVENT_TYPE_INDEX = labels.index('eventType')\n",
    "\n",
    "# from line in .bac file\n",
    "LOG_LEVEL_START = 0\n",
    "LOG_LEVEL_END = 3\n",
    "TIMESTAMP_START = 6\n",
    "TIMESTAMP_END = 14\n",
    "PIPE_SEPARATED_DATA_START = 17\n",
    "\n",
    "event_type_labels = [\n",
    "    \"string message\", # GeneralMessage\n",
    "    \"load ID\", \"loadName\", \"roomName1\", \"rampTime\", \"rampBaseValue\", \"rampFinalValue\", # LevelChangedEvent\n",
    "    \"keypad ID\", \"keypadName\", \"roomName2\", \"buttonNum\", \"buttonState\", # ButtonChangedEvent\n",
    "    \"signalID\", \"signalName\", \"roomName3\", \"RemoteSystemEvent string\", # RemoteSystemEvent\n",
    "    \"ID\", \"name\", \"roomName4\", \"message1\", # TimeClockChangedEvent/OccupancyChangedEvent/SceneChangedEvent\n",
    "    \"device ID1\", \"Name\", \"roomName5\", \"connection status\", \"Load 1 Room Name:Load 1 Name\", \"Load 2 Room Name:Load 2 Name\", # ConnectionStatus/DeviceConnectionStatusWithOptions\n",
    "    \"device ID2\", \"Device Name1\", \"roomName6\", \"signal event ID\", \"signal Value\", # SignalChangedEvent\n",
    "    \"device ID3\", \"Device Name2\", \"Signal Name\", \"Signal Value string\", \"Signal direction\", \"message2\", # SignalChangedEventWithStrings\n",
    "]\n",
    "\n",
    "def from_bac():\n",
    "    # device_id_offsets = [i for i, x in enumerate(event_type_labels) if x == \"device ID\"]\n",
    "    clean_lines = []\n",
    "\n",
    "    for log in os.listdir('data'):\n",
    "        with open('data/{}'.format(log)) as logfile:\n",
    "            for line in logfile:\n",
    "                line = line.rstrip('\\n')\n",
    "                if line[-1] == '|':\n",
    "                    line = line[:-1]\n",
    "                all_data = ([line[LOG_LEVEL_START:LOG_LEVEL_END], line[TIMESTAMP_START:TIMESTAMP_END]]\n",
    "                            + line[PIPE_SEPARATED_DATA_START:].split('|'))\n",
    "\n",
    "                event_type_dependent_strings = all_data[len(labels):]\n",
    "                clean_line = all_data[:len(labels)]\n",
    "\n",
    "                START_INDEX = 7\n",
    "                if clean_line[EVENT_TYPE_INDEX] == 'GeneralMessage':\n",
    "                    START_INDEX += event_type_labels.index('string message')\n",
    "                    # account for pipes in the message string\n",
    "                    event_type_dependent_strings = ['|'.join(event_type_dependent_strings)]\n",
    "                    assert START_INDEX == 7\n",
    "                    assert len(event_type_dependent_strings) == 1, event_type_dependent_strings\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'LevelChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('load ID')\n",
    "                    assert START_INDEX == 8\n",
    "                    assert len(event_type_dependent_strings) == 6\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'ButtonChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('keypad ID')\n",
    "                    assert START_INDEX == 14\n",
    "                    assert len(event_type_dependent_strings) == 5\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'RemoteSystemEvent':\n",
    "                    START_INDEX += event_type_labels.index('signalID')\n",
    "                    assert START_INDEX == 19\n",
    "                    assert len(event_type_dependent_strings) == 4\n",
    "\n",
    "                elif (clean_line[EVENT_TYPE_INDEX] == 'TimeClockChangedEvent' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'OccupancyChangedEvent' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'SceneChangedEvent'):\n",
    "                    START_INDEX += event_type_labels.index('ID')\n",
    "                    assert START_INDEX == 23\n",
    "                    assert len(event_type_dependent_strings) == 4\n",
    "\n",
    "                elif (clean_line[EVENT_TYPE_INDEX] == 'ConnectionStatus' or\n",
    "                      clean_line[EVENT_TYPE_INDEX] == 'DeviceConnectionStatusWithOptions'):\n",
    "                    START_INDEX += event_type_labels.index('device ID1')\n",
    "                    assert START_INDEX == 27\n",
    "                    assert (len(event_type_dependent_strings) == 4 or\n",
    "                            len(event_type_dependent_strings) == 5 or\n",
    "                            len(event_type_dependent_strings) == 6)\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'SignalChangedEvent':\n",
    "                    START_INDEX += event_type_labels.index('device ID2')\n",
    "                    assert START_INDEX == 33\n",
    "                    assert len(event_type_dependent_strings) == 5\n",
    "\n",
    "                elif clean_line[EVENT_TYPE_INDEX] == 'SignalChangedEventWithStrings':\n",
    "                    START_INDEX += event_type_labels.index('device ID3')\n",
    "                    assert START_INDEX == 38\n",
    "                    # to correct for the double pipe in \"Basement Mudroom\"\n",
    "                    event_type_dependent_strings = [i for i in event_type_dependent_strings if i]\n",
    "                else:\n",
    "                    raise ValueError(\"Wrong event type: {}\".format(clean_line[EVENT_TYPE_INDEX]))\n",
    "\n",
    "                clean_line = clean_line + [np.nan]*len(event_type_labels) + [log[-14:-4]]\n",
    "                clean_line[START_INDEX:START_INDEX + len(event_type_dependent_strings)] = event_type_dependent_strings\n",
    "                clean_lines.append(clean_line)\n",
    "    df = pd.DataFrame(clean_lines, columns=labels + event_type_labels + [\"date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from BAC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = from_bac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(row):\n",
    "    new_date = row['date'] + ' ' + row['TimeStamp']\n",
    "    dt = datetime.strptime(new_date, '%Y-%m-%d %H:%M:%S')\n",
    "    dt = dt + timedelta(hours=4)\n",
    "    unix_secs = mktime(dt.timetuple())\n",
    "    return unix_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unix_time'] = df.apply(to_datetime, axis=1)\n",
    "df = df.drop([\"TimeStamp\",\"date\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useless columns\n",
    "df = df.drop([\"LogLevel\", \"LogVisibility\", \"LogSeverity\"],axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting General Message\n",
    "df = df.drop(\"string message\", axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Button Change Event\n",
    "df = df.drop([\"keypad ID\", \"keypadName\", \"roomName2\", \"buttonNum\", \"buttonState\"], axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Connection Status\n",
    "df = df.drop([\"device ID1\", \"Name\", \"roomName5\", \"connection status\", \"Load 1 Room Name:Load 1 Name\", \"Load 2 Room Name:Load 2 Name\"], axis=1, errors='ignore')\n",
    "\n",
    "# useless after deleting Remote System Event\n",
    "df = df.drop([\"signalID\", \"signalName\", \"roomName3\", \"RemoteSystemEvent string\"], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove useless event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['eventType'] != 'ButtonChangedEvent']\n",
    "df = df[df['eventType'] != 'GeneralMessage']\n",
    "df = df[df['eventType'] != 'RemoteSystemEvent']\n",
    "df = df[df['eventType'] != 'TimeClockChangedEvent']\n",
    "df = df[df['eventType'] != 'ConnectionStatus']\n",
    "df = df[df['eventType'] != 'DeviceConnectionStatusWithOptions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Ids and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(row, *args):\n",
    "    count = sum(1 for column_name in args if pd.notna(row[column_name]))\n",
    "    # checks if more than one value in the merged rows\n",
    "    assert count < 2\n",
    "    for column_name in args:\n",
    "        if pd.notna(row[column_name]):\n",
    "            return row[column_name]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge room names\n",
    "df['room_name_merged'] = df.apply(merge_columns, args=(\"roomName1\",\"roomName4\",\"roomName6\"), axis=1)\n",
    "df = df.drop([\"roomName1\",\"roomName4\",\"roomName6\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge device name\n",
    "df['device_name'] = df.apply(merge_columns, args=(\"loadName\", \"name\", \"Device Name1\", \"Device Name2\"), axis=1)\n",
    "df = df.drop([\"loadName\", \"name\", \"Device Name1\", \"Device Name2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge IDs \n",
    "df['device_id'] = df.apply(merge_columns, args=('load ID', 'ID', 'device ID2', 'device ID3'), axis=1)\n",
    "df = df.drop(['load ID', 'ID', 'device ID2', 'device ID3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge messages \n",
    "df['message_merged'] = df.apply(merge_columns, args=(\"message1\", \"message2\"), axis=1)\n",
    "df = df.drop([\"message1\", \"message2\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine device name and id to for truly unique ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['device_id_name'] = df['device_id'].astype(str) + df['device_name'].astype(str)\n",
    "df = df.drop([\"device_id\", \"device_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint \n",
    "df = save_or_load_from_checkpoint('./checkpoints/data_1.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping more useless data\n",
    "index_to_drop = df.loc[df[\"entryType\"] == \"Auxiliary\"][df['eventType'] == \"SignalChangedEventWithStrings\"].index.tolist()\n",
    "df = df.drop(index_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    signal_direction = str(row['Signal direction'])\n",
    "    if 'Fahrenheit' in signal_direction and signal_direction[0].isdigit():\n",
    "        temp = int(''.join(x for x in signal_direction if x.isdigit()))\n",
    "        df.at[index, 'temperature'] = temp\n",
    "        \n",
    "    if len(signal_direction) > 20:\n",
    "        heat_cool_auto = signal_direction.split(',')\n",
    "        heat_temp = [int(s[:-1]) for s in heat_cool_auto[0].split() if s[0].isdigit()]\n",
    "        cool_temp = [int(s[:-1]) for s in heat_cool_auto[1].split() if s[0].isdigit()]\n",
    "        auto_temp = [int(s[:-1]) for s in heat_cool_auto[2].split() if s[0].isdigit()]\n",
    "        df.at[index, 'heat_setpoint'] = heat_temp[0]\n",
    "        df.at[index, 'cool_setpoint'] = cool_temp[0]\n",
    "        df.at[index, 'auto_setpoint'] = auto_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_or_load_from_checkpoint('./checkpoints/data_2.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize values for binary and regression event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add week, day, month, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(data_frame):\n",
    "    date = pd.to_datetime(data_frame['unix_time'], unit='s')\n",
    "    data_frame['week'] = date.dt.week\n",
    "    data_frame['day'] = date.dt.day\n",
    "    data_frame['month'] = date.dt.month\n",
    "    data_frame['hour'] = date.dt.hour\n",
    "    data_frame['minute'] = date.dt.minute\n",
    "    data_frame['second'] = date.dt.second\n",
    "    return data_frame\n",
    "\n",
    "df = add_dates(df)\n",
    "df = df.drop('unix_time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add temperature, sunrise/sunset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_http = 'https://api.darksky.net/forecast/a6861bbd8dfb09d9f06714ba8485934f/39.833851,-74.871826,'\n",
    "temp_time_dict = {}\n",
    "\n",
    "def create_weather_sunset_columns(row):\n",
    "    #hard-coded year for now. \n",
    "    date_obj = datetime.date(2017, row['month'], row['day'])\n",
    "    #format for API\n",
    "    current_timestamp = int(time.mktime(date_obj.timetuple())) + 4 * 60 * 60\n",
    "\n",
    "    if not current_timestamp in temp_time_dict.keys():\n",
    "        r = requests.get(base_http + str(current_timestamp))\n",
    "        temp_json = r.json()\n",
    "        temp_time_dict[current_timestamp] = temp_json\n",
    "\n",
    "    temperature_info = temp_time_dict[current_timestamp]['hourly']['data'][row['hour']]['temperature']\n",
    "\n",
    "    sunrise = temp_time_dict[current_timestamp]['daily']['data'][0]['sunriseTime'] #in GMT \n",
    "    sunset = temp_time_dict[current_timestamp]['daily']['data'][0]['sunsetTime']\n",
    "    current_timestamp_with_seconds = current_timestamp + (row['hour'] * 60 * 60) + (row['minute'] * 60)\n",
    "\n",
    "    is_sun_up = 1 if sunrise <= current_timestamp_with_seconds <= sunset else 0\n",
    "    return is_sun_up, temperature_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sun'], df['outside_temperature'] = zip(*df.apply(create_weather_sunset_columns, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = save_or_load_from_checkpoint('./checkpoints/data_4.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Encode Columns\n",
    "\n",
    "Convert Categorical to Numerical Data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "columns_to_update = [\"entryType\", \"entrySubType\", \"device_id_name\", \"eventType\", \"Signal Name\", \"Signal Value string\", \"Signal direction\", \"room_name_merged\", \"message_merged\"]\n",
    "\n",
    "def encode_columns(data_frame, column_names):\n",
    "    label_encoders = {}\n",
    "    for col in column_names:\n",
    "        values = data_frame[col].unique()\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(values)\n",
    "        label_encoders[col] = le\n",
    "        numerical_values = le.transform(data_frame[col])\n",
    "        data_frame[col] = numerical_values\n",
    "    return data_frame, label_encoders\n",
    "\n",
    "categorical_df = df.copy()\n",
    "categorical_df, label_encoders = encode_columns(categorical_df, columns_to_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
